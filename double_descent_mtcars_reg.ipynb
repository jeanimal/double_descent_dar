{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This notebook illustrates the bias-variance trade-off and double descent in a linear regression model.  Double descent means that test (out-of-sample) error can sometimes be reduced by adding more parameters to the model, contrary to the traditional bias-variance U curves that argued for a \"sweet spot\" at a fewer number of parameters.  Originally, double descent was only believed to exist for deep neural nets, but a paper by Dar et al. found it in linear regression.  But is it real in linear regression or a statistical artifact?  Read more below.",
   "id": "cd03d0be01071c04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Libraries",
   "id": "fae063846b830307"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.226205Z",
     "start_time": "2024-08-07T14:32:11.878159Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data set",
   "id": "eed787219daef47c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here I load a data set to analyze.  In an earlier R version of this notebook, I used the \"mtcars\" data set which has data on various models in Motor Trend cars of the year.\n",
    "\n",
    "The goal is to predict the miles per gallon (mpg) of various models based on their other characteristics."
   ],
   "id": "f801e81d8967712f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.243519Z",
     "start_time": "2024-08-07T14:32:13.232791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "notebook_path = os.path.abspath(\"double_descent_mtcars_reg.ipynb\")\n",
    "print(notebook_path)\n",
    "csv_path = os.path.join(os.path.dirname(notebook_path), \"data/mt_cars.csv\")\n",
    "print(csv_path)"
   ],
   "id": "2f6b82fc51e0d3b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jeanortega/PycharmProjects/pythonProject1/double_descent_mtcars_reg.ipynb\n",
      "/Users/jeanortega/PycharmProjects/pythonProject1/data/mt_cars.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.254760Z",
     "start_time": "2024-08-07T14:32:13.245197Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(csv_path)",
   "id": "17f671c041e3a9f3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.271208Z",
     "start_time": "2024-08-07T14:32:13.255661Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "6c74bee6a1a3c3c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  model   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  \\\n",
       "0             Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1   \n",
       "1         Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1   \n",
       "2            Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1   \n",
       "3        Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0   \n",
       "4     Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0   \n",
       "5               Valiant  18.1    6  225.0  105  2.76  3.460  20.22   1   0   \n",
       "6            Duster 360  14.3    8  360.0  245  3.21  3.570  15.84   0   0   \n",
       "7             Merc 240D  24.4    4  146.7   62  3.69  3.190  20.00   1   0   \n",
       "8              Merc 230  22.8    4  140.8   95  3.92  3.150  22.90   1   0   \n",
       "9              Merc 280  19.2    6  167.6  123  3.92  3.440  18.30   1   0   \n",
       "10            Merc 280C  17.8    6  167.6  123  3.92  3.440  18.90   1   0   \n",
       "11           Merc 450SE  16.4    8  275.8  180  3.07  4.070  17.40   0   0   \n",
       "12           Merc 450SL  17.3    8  275.8  180  3.07  3.730  17.60   0   0   \n",
       "13          Merc 450SLC  15.2    8  275.8  180  3.07  3.780  18.00   0   0   \n",
       "14   Cadillac Fleetwood  10.4    8  472.0  205  2.93  5.250  17.98   0   0   \n",
       "15  Lincoln Continental  10.4    8  460.0  215  3.00  5.424  17.82   0   0   \n",
       "16    Chrysler Imperial  14.7    8  440.0  230  3.23  5.345  17.42   0   0   \n",
       "17             Fiat 128  32.4    4   78.7   66  4.08  2.200  19.47   1   1   \n",
       "18          Honda Civic  30.4    4   75.7   52  4.93  1.615  18.52   1   1   \n",
       "19       Toyota Corolla  33.9    4   71.1   65  4.22  1.835  19.90   1   1   \n",
       "20        Toyota Corona  21.5    4  120.1   97  3.70  2.465  20.01   1   0   \n",
       "21     Dodge Challenger  15.5    8  318.0  150  2.76  3.520  16.87   0   0   \n",
       "22          AMC Javelin  15.2    8  304.0  150  3.15  3.435  17.30   0   0   \n",
       "23           Camaro Z28  13.3    8  350.0  245  3.73  3.840  15.41   0   0   \n",
       "24     Pontiac Firebird  19.2    8  400.0  175  3.08  3.845  17.05   0   0   \n",
       "25            Fiat X1-9  27.3    4   79.0   66  4.08  1.935  18.90   1   1   \n",
       "26        Porsche 914-2  26.0    4  120.3   91  4.43  2.140  16.70   0   1   \n",
       "27         Lotus Europa  30.4    4   95.1  113  3.77  1.513  16.90   1   1   \n",
       "28       Ford Pantera L  15.8    8  351.0  264  4.22  3.170  14.50   0   1   \n",
       "29         Ferrari Dino  19.7    6  145.0  175  3.62  2.770  15.50   0   1   \n",
       "30        Maserati Bora  15.0    8  301.0  335  3.54  3.570  14.60   0   1   \n",
       "31           Volvo 142E  21.4    4  121.0  109  4.11  2.780  18.60   1   1   \n",
       "\n",
       "    gear  carb  \n",
       "0      4     4  \n",
       "1      4     4  \n",
       "2      4     1  \n",
       "3      3     1  \n",
       "4      3     2  \n",
       "5      3     1  \n",
       "6      3     4  \n",
       "7      4     2  \n",
       "8      4     2  \n",
       "9      4     4  \n",
       "10     4     4  \n",
       "11     3     3  \n",
       "12     3     3  \n",
       "13     3     3  \n",
       "14     3     4  \n",
       "15     3     4  \n",
       "16     3     4  \n",
       "17     4     1  \n",
       "18     4     2  \n",
       "19     4     1  \n",
       "20     3     1  \n",
       "21     3     2  \n",
       "22     3     2  \n",
       "23     3     4  \n",
       "24     3     2  \n",
       "25     4     1  \n",
       "26     5     2  \n",
       "27     5     2  \n",
       "28     5     4  \n",
       "29     5     6  \n",
       "30     5     8  \n",
       "31     4     2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Valiant</td>\n",
       "      <td>18.1</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.460</td>\n",
       "      <td>20.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Duster 360</td>\n",
       "      <td>14.3</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.570</td>\n",
       "      <td>15.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Merc 240D</td>\n",
       "      <td>24.4</td>\n",
       "      <td>4</td>\n",
       "      <td>146.7</td>\n",
       "      <td>62</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.190</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Merc 230</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>140.8</td>\n",
       "      <td>95</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.150</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Merc 280</td>\n",
       "      <td>19.2</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Merc 280C</td>\n",
       "      <td>17.8</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Merc 450SE</td>\n",
       "      <td>16.4</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.070</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Merc 450SL</td>\n",
       "      <td>17.3</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.730</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Merc 450SLC</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.780</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cadillac Fleetwood</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>472.0</td>\n",
       "      <td>205</td>\n",
       "      <td>2.93</td>\n",
       "      <td>5.250</td>\n",
       "      <td>17.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lincoln Continental</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>460.0</td>\n",
       "      <td>215</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.424</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chrysler Imperial</td>\n",
       "      <td>14.7</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>230</td>\n",
       "      <td>3.23</td>\n",
       "      <td>5.345</td>\n",
       "      <td>17.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fiat 128</td>\n",
       "      <td>32.4</td>\n",
       "      <td>4</td>\n",
       "      <td>78.7</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.200</td>\n",
       "      <td>19.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Honda Civic</td>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.7</td>\n",
       "      <td>52</td>\n",
       "      <td>4.93</td>\n",
       "      <td>1.615</td>\n",
       "      <td>18.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Toyota Corolla</td>\n",
       "      <td>33.9</td>\n",
       "      <td>4</td>\n",
       "      <td>71.1</td>\n",
       "      <td>65</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.835</td>\n",
       "      <td>19.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Toyota Corona</td>\n",
       "      <td>21.5</td>\n",
       "      <td>4</td>\n",
       "      <td>120.1</td>\n",
       "      <td>97</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.465</td>\n",
       "      <td>20.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dodge Challenger</td>\n",
       "      <td>15.5</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.520</td>\n",
       "      <td>16.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AMC Javelin</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.435</td>\n",
       "      <td>17.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Camaro Z28</td>\n",
       "      <td>13.3</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.840</td>\n",
       "      <td>15.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pontiac Firebird</td>\n",
       "      <td>19.2</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.845</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Fiat X1-9</td>\n",
       "      <td>27.3</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.935</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Porsche 914-2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.3</td>\n",
       "      <td>91</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.140</td>\n",
       "      <td>16.70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lotus Europa</td>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>95.1</td>\n",
       "      <td>113</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.513</td>\n",
       "      <td>16.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ford Pantera L</td>\n",
       "      <td>15.8</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>264</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.170</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ferrari Dino</td>\n",
       "      <td>19.7</td>\n",
       "      <td>6</td>\n",
       "      <td>145.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.770</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Maserati Bora</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>301.0</td>\n",
       "      <td>335</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.570</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Volvo 142E</td>\n",
       "      <td>21.4</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>109</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.780</td>\n",
       "      <td>18.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Split X and y",
   "id": "8e4443878d3f6bf2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we put the data in a standard format for analysis.  If you load your own data set, you will need to tweak the target column and remove the non-numeric columns-- or code them, e.g. with one-hot encoding.",
   "id": "e7d0726fac745221"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.278797Z",
     "start_time": "2024-08-07T14:32:13.276226Z"
    }
   },
   "cell_type": "code",
   "source": "TARGET_COL = \"mpg\"",
   "id": "ca86d4b670951c61",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.283387Z",
     "start_time": "2024-08-07T14:32:13.280006Z"
    }
   },
   "cell_type": "code",
   "source": "NON_NUMERIC_COLS = [\"model\"]",
   "id": "f9089e353c5ac8e1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.290079Z",
     "start_time": "2024-08-07T14:32:13.285370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = df[TARGET_COL]\n",
    "X = df.drop([TARGET_COL] + NON_NUMERIC_COLS,axis=1)"
   ],
   "id": "e00f0ccf1b3a4c09",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Functions",
   "id": "4ee9d64483e400ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.292173Z",
     "start_time": "2024-08-07T14:32:13.290867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random_state = 10 # For reproducibility\n",
    "num_sampled_rows = 4\n",
    "num_sampled_columns = 5"
   ],
   "id": "e6ee2422a8f1929",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.295880Z",
     "start_time": "2024-08-07T14:32:13.292783Z"
    }
   },
   "cell_type": "code",
   "source": "indices = np.random.choice(df.index, num_sampled_rows, replace=False)",
   "id": "44d182cc658e7576",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.298708Z",
     "start_time": "2024-08-07T14:32:13.296381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# X_subset = X.sample(n=num_sampled_rows, random_state=random_state, axis=0)\n",
    "X_subset = X.iloc[indices]\n",
    "y_subset = y.iloc[indices]"
   ],
   "id": "32a80b5e4f685da2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.301136Z",
     "start_time": "2024-08-07T14:32:13.299157Z"
    }
   },
   "cell_type": "code",
   "source": "X_subset = X_subset.sample(n=num_sampled_columns, random_state=random_state, axis=1)",
   "id": "6b43c71651b65f7c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.304711Z",
     "start_time": "2024-08-07T14:32:13.301535Z"
    }
   },
   "cell_type": "code",
   "source": "X_subset",
   "id": "a54d18234f818324",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    gear   hp   qsec  vs  drat\n",
       "24     3  175  17.05   0  3.08\n",
       "18     4   52  18.52   1  4.93\n",
       "0      4  110  16.46   0  3.90\n",
       "15     3  215  17.82   0  3.00"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gear</th>\n",
       "      <th>hp</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>drat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>18.52</td>\n",
       "      <td>1</td>\n",
       "      <td>4.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>215</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.309516Z",
     "start_time": "2024-08-07T14:32:13.305159Z"
    }
   },
   "cell_type": "code",
   "source": "y_subset",
   "id": "dbe431bec849fce0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    19.2\n",
       "18    30.4\n",
       "0     21.0\n",
       "15    10.4\n",
       "Name: mpg, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Using the package",
   "id": "74ae41d1aa6acc6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I have a little package to help sample a dataframe in a way that makes it easy to create conditions for the underfitting, interpolation, and overfitting regime.",
   "id": "5834a459151175e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.322349Z",
     "start_time": "2024-08-07T14:32:13.317902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The simplest way to make this reproducible.\n",
    "np.random.seed(0)"
   ],
   "id": "4ccee23df7f11af0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.335226Z",
     "start_time": "2024-08-07T14:32:13.324987Z"
    }
   },
   "cell_type": "code",
   "source": "from double_descent_dar import sample_eval",
   "id": "6d962fdbb201615a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.341740Z",
     "start_time": "2024-08-07T14:32:13.337373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random_state = None # Set for reproducibility\n",
    "num_sampled_rows = 3\n",
    "num_sampled_columns = 4"
   ],
   "id": "8f6c7152a2a68f52",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.350602Z",
     "start_time": "2024-08-07T14:32:13.343952Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = sample_eval.train_test_split_by_rows_and_cols(X, y, num_train_rows=num_sampled_rows, num_columns=num_sampled_columns, replace=False, random_state=random_state, verbose=True)",
   "id": "fddfb904178f467c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using train_size 0.09375\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.360597Z",
     "start_time": "2024-08-07T14:32:13.351483Z"
    }
   },
   "cell_type": "code",
   "source": "X_train",
   "id": "30d9414e82534d94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     hp  gear    wt  carb\n",
       "6   245     3  3.57     4\n",
       "23  245     3  3.84     4\n",
       "4   175     3  3.44     2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hp</th>\n",
       "      <th>gear</th>\n",
       "      <th>wt</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>245</td>\n",
       "      <td>3</td>\n",
       "      <td>3.57</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>245</td>\n",
       "      <td>3</td>\n",
       "      <td>3.84</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175</td>\n",
       "      <td>3</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.369788Z",
     "start_time": "2024-08-07T14:32:13.362962Z"
    }
   },
   "cell_type": "code",
   "source": "y_train",
   "id": "92fd45fdcd4f03aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     14.3\n",
       "23    13.3\n",
       "4     18.7\n",
       "Name: mpg, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "What we will do is fit a linear regression on this data and then measure out of sample error.\n",
   "id": "f4460d9477b640f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.376296Z",
     "start_time": "2024-08-07T14:32:13.372109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model = RandomForestRegressor()\n",
    "# model = linear_model.Ridge(alpha=.5)\n",
    "model = linear_model.LinearRegression(fit_intercept=True)"
   ],
   "id": "f62fd18d90e7a6fe",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.402848Z",
     "start_time": "2024-08-07T14:32:13.379311Z"
    }
   },
   "cell_type": "code",
   "source": "model.fit(X_train, y_train)",
   "id": "e64308095bccd89f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.410202Z",
     "start_time": "2024-08-07T14:32:13.405692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# my_metric = root_mean_squared_error\n",
    "my_metric = mean_absolute_error"
   ],
   "id": "10d9b7f0d2e577e5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.416667Z",
     "start_time": "2024-08-07T14:32:13.412142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_error = my_metric(y_train, model.predict(X_train))\n",
    "train_error"
   ],
   "id": "726945e27ad5b70e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.423159Z",
     "start_time": "2024-08-07T14:32:13.417806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_error = my_metric(y_test, model.predict(X_test))\n",
    "test_error"
   ],
   "id": "b54bc935c4ed9d33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.7667122936628337)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As expected, train error (in-sample fit) is lower than test error (out of sample).",
   "id": "5fd8cc416c9453b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will do this again and again and look at the average metric value for combinations of number of rows and columns.",
   "id": "fdb3ef5b982c73a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bias-variance U curve",
   "id": "468c3f23c238ddb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Seeing a traditional bias-variance U curve requires that the number of parameters should be a lot less than the number of rows.  Since the data set has 9 columns, we will need a lot more rows. This section will sample 15 rows (out of a total of 32) to train on.\n",
    "\n",
    "We will sample between 2 and 8 columns (out of a total of 10 numeric columns) to see how the error metric varies by the number of parameters."
   ],
   "id": "feedcfd9e6d0f44a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that the regression used here includes an intercept, so 8 columns + 1 intercept -> 9 parameters.  With 15 rows to train on, full interpolation would be reached with 15 columns.",
   "id": "6f14289cbf6c79cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.427665Z",
     "start_time": "2024-08-07T14:32:13.423655Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "7492ae8aeb7c67a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.431086Z",
     "start_time": "2024-08-07T14:32:13.429163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_train_rows = 15\n",
    "num_sampled_columns = 3"
   ],
   "id": "70069146462259c6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.437298Z",
     "start_time": "2024-08-07T14:32:13.431604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = sample_eval.train_test_split_by_rows_and_cols(X, y, num_train_rows=num_train_rows, num_columns=num_sampled_columns, replace=False, random_state=random_state, verbose=True)\n",
    "X_train"
   ],
   "id": "c7a64a9d48101a20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using train_size 0.46875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     disp  gear  carb\n",
       "18   75.7     4     2\n",
       "1   160.0     4     4\n",
       "10  167.6     4     4\n",
       "9   167.6     4     4\n",
       "29  145.0     5     6\n",
       "15  460.0     3     4\n",
       "17   78.7     4     1\n",
       "20  120.1     3     1\n",
       "8   140.8     4     2\n",
       "6   360.0     3     4\n",
       "5   225.0     3     1\n",
       "21  318.0     3     2\n",
       "4   360.0     3     2\n",
       "31  121.0     4     2\n",
       "0   160.0     4     4"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disp</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75.7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>167.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>167.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>145.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>460.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>78.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>120.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>140.8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>360.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>225.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>318.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>121.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:13.439863Z",
     "start_time": "2024-08-07T14:32:13.438391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_by_num_cols(num_sampled_columns_local):\n",
    "    return sample_eval.sample_and_calc_metric_by_rows_and_cols(X, y, num_train_rows=num_train_rows, num_columns=num_sampled_columns_local, model=model, metric_func=my_metric, replace=False, random_state=random_state)['test']"
   ],
   "id": "470c0a2cf691d5a5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:21.971421Z",
     "start_time": "2024-08-07T14:32:13.440300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_samples = 1000\n",
    "metric_all_samples = []\n",
    "for num_sampled_columns in range(1, X.shape[1]-1):\n",
    "    metric_all_samples.append((num_sampled_columns, [sample_by_num_cols(num_sampled_columns) for _ in range(num_samples)]))"
   ],
   "id": "d7325206424428ea",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:21.975505Z",
     "start_time": "2024-08-07T14:32:21.972568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key, values in metric_all_samples:\n",
    "    the_mean = np.mean(values)\n",
    "    the_stdev = np.std(values)\n",
    "    print(f'num_cols: {key}, mean error: {the_mean:9.3f}, stdev of error: {the_stdev:4.1f}')"
   ],
   "id": "dbf9285b78f9aad0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols: 1, mean error:     3.699, stdev of error:  0.9\n",
      "num_cols: 2, mean error:     3.134, stdev of error:  0.8\n",
      "num_cols: 3, mean error:     2.877, stdev of error:  0.6\n",
      "num_cols: 4, mean error:     2.773, stdev of error:  0.6\n",
      "num_cols: 5, mean error:     2.900, stdev of error:  0.7\n",
      "num_cols: 6, mean error:     3.081, stdev of error:  0.9\n",
      "num_cols: 7, mean error:     3.376, stdev of error:  1.3\n",
      "num_cols: 8, mean error:     3.784, stdev of error:  1.6\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:21.978503Z",
     "start_time": "2024-08-07T14:32:21.976191Z"
    }
   },
   "cell_type": "code",
   "source": "metric_means = [(col_val_tuple[0], np.mean(col_val_tuple[1])) for col_val_tuple in metric_all_samples]",
   "id": "f451a12836473549",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:21.980431Z",
     "start_time": "2024-08-07T14:32:21.979010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = list(zip(*metric_means))\n",
    "num_cols = res[0]\n",
    "means = res[1]"
   ],
   "id": "cb17a7d97a7ad5b9",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:21.982836Z",
     "start_time": "2024-08-07T14:32:21.981025Z"
    }
   },
   "cell_type": "code",
   "source": "my_metric.__name__",
   "id": "1c71c61f70371b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean_absolute_error'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:22.060474Z",
     "start_time": "2024-08-07T14:32:21.983249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.scatter(num_cols, means)\n",
    "plt.xlabel(\"Num sampled columns\")\n",
    "plt.ylabel(\"Mean of \" + my_metric.__name__)\n",
    "plt.show()"
   ],
   "id": "a458ae115d906c9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "That is a beautiful U shape.  The linear regression's lowest average test (out-of-sample) error was achieved at 4 columns, which with the intercept means 5 parameters to fit.  This is much less than the 9 columns available in the data set.\n",
    "\n",
    "(There is no simple theory that predicts what the optimal number of parameters will be.) "
   ],
   "id": "aefb99dddbc20e07"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Double descent",
   "id": "403b642f573546b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A paper by Dar et al. (), called \"Farewell to Bias Variance?\" showed mathematically that double descent could be exhibited by linear regression under certain conditions. \n",
    "\n",
    "The paper: \n",
    "Yehuda Dar, Muthukumar, V., & Baraniuk, R. (2021). A Farewell to the Bias-Variance Tradeoff? An Overview of the Theory of Overparameterized Machine Learning. https://arxiv.org/abs/2109.02355\n"
   ],
   "id": "d6197abaf8b716c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here I show double descent empirically on the mtcars data set (widely used by R users).",
   "id": "b9c477192eeba6f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Seeing double descent requires that the number of parameters should be a lot MORE than the number of rows. Since the data set has only 9 columns, we achieve this with a trick-- sampling fewer rows.\n",
    "\n",
    "This section will sample 14 rows (out of a total of 32) and then use a 50% train/test split, resulting in 7 rows to train on.\n",
    "\n",
    "As before, will sample between 2 and 8 columns (out of a total of 9 columns) to see how the error metric varies by the number of parameters.  "
   ],
   "id": "b65d29fbef9694e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The linear regression model will be able to fully interpolate the data at N=6 columns because that results in N+1=7 parameters to be fit to the 7 rows.",
   "id": "e42159c2bbfc8fd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:22.218450Z",
     "start_time": "2024-08-07T14:32:22.061251Z"
    }
   },
   "cell_type": "code",
   "source": "train_test_df = run_multiple_samples()",
   "id": "5c8d6e0c56df9462",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_multiple_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_test_df \u001B[38;5;241m=\u001B[39m \u001B[43mrun_multiple_samples\u001B[49m()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'run_multiple_samples' is not defined"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "num_sampled_rows = 14",
   "id": "94f7bb946771084c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_by_num_cols(num_sampled_columns_local):\n",
    "    return sample_eval.sample_and_calc_metric(X, y, num_sampled_rows, num_sampled_columns_local, train_proportion, model, my_metric, replace=False, random_state=random_state)['test']"
   ],
   "id": "a7a044ef68e6d4e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_samples = 200\n",
    "train_proportion = 0.5\n",
    "metric_all_samples = []\n",
    "for num_sampled_columns in range(1, X.shape[1]-1):\n",
    "    metric_all_samples.append((num_sampled_columns, [sample_by_num_cols(num_sampled_columns) for _ in range(num_samples)]))"
   ],
   "id": "c3ab2f48527b1bda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metric_means = [(col_val_tuple[0], np.mean(col_val_tuple[1])) for col_val_tuple in metric_all_samples]",
   "id": "378479adc04724d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = list(zip(*metric_means))\n",
    "num_cols = res[0]\n",
    "means = res[1]"
   ],
   "id": "2cce0524174081f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.scatter(num_cols, means)\n",
    "plt.xlabel(\"Num sampled columns\")\n",
    "plt.ylabel(\"Mean of \" + my_metric.__name__)\n",
    "plt.show()"
   ],
   "id": "80257d46b7fb5b39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As predicted, there was a spike in test (out of sample) error when sampling 6 columns.  The fitting method is highly unstable here due to full interpolation.  Error descends a second time after this threshold-- so we observe classic double descent-- formerly thought of a neural net feature-- with simple, traditional linear regression.",
   "id": "c725d60c9915cc9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Double descent is actually two U curves in linear regression",
   "id": "c814ce67f43f1b60"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A recent paper pointed out that different fitting methods are used on different sides of the interpolation threshold in linear regression.  When the number of rows N > number of paramters p, the best estimator involves inverting the N x p matrix.  But a matrix with more columns than rows cannot be inverted, so other parameter estimation methods are required.  The paper argues that it is this change in estimation methods that produces the two humps.  Each estimation method on its own has a U-shaped bias-variance curve, and the so-called double descent shape is just blending these two U's.\n",
    "\n",
    "The paper:\n",
    "Curth, A., Jeffares, A., & Schaar, M. van der. (2023, November 2). A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning. Thirty-seventh Conference on Neural Information Processing Systems. https://openreview.net/forum?id=O0Lz8XZT2b\n"
   ],
   "id": "ac769a2e5ce49eed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Double descent in linear regression s real",
   "id": "8ac681b0415b91d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here I address that point by using a version of linear regression that uses the same estimation method on both sides of the interpolation threshold-- stochastic gradient descent (SGD), the same method used by neural nets.  The Curth et al argument only applies to cases where two different estimation methods are used, but gradient descent can apply to all shapes of the data matrix.\n",
    "\n",
    "Notes:\n",
    "* The SGDRegressor assumes input has been scaled from 0 to 1, so I wrap it inside a pipeline to handle scaling.\n",
    "* By default the SGDRegressor includes regularization, so to make it comparable to the pure LinearRegression example above, I have to set the penatly to None."
   ],
   "id": "4c0c8109feb291ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = make_pipeline(StandardScaler(), SGDRegressor(random_state=0, penalty=None))"
   ],
   "id": "305f5ef59bd739e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "num_sampled_rows = 30",
   "id": "23bfb1cecdc2a4f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_by_num_cols(num_sampled_columns_local):\n",
    "    return sample_eval.sample_and_calc_metric(X, y, num_sampled_rows, num_sampled_columns_local, train_proportion, model, my_metric, replace=False, random_state=random_state)['test']\n",
    "num_samples = 300\n",
    "train_proportion = 0.5\n",
    "metric_all_samples = []\n",
    "# This example won't converge because we have such a small data sst\n",
    "# so we catch the warning and ignore it here.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    for num_sampled_columns in range(1, X.shape[1]-1):\n",
    "        metric_all_samples.append((num_sampled_columns, [sample_by_num_cols(num_sampled_columns) for _ in range(num_samples)]))\n",
    "metric_means = [(col_val_tuple[0], np.mean(col_val_tuple[1])) for col_val_tuple in metric_all_samples]\n",
    "res = list(zip(*metric_means))\n",
    "num_cols = res[0]\n",
    "means = res[1]\n",
    "plt.scatter(num_cols, means)\n",
    "plt.xlabel(\"Num sampled columns\")\n",
    "plt.ylabel(\"Mean of \" + my_metric.__name__)\n",
    "plt.show()"
   ],
   "id": "720e02a499aa74ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Nice!  This is the \"left\" half of a U curve.  It minimizes test (out-of-sample) error with 5 columns.",
   "id": "60f939d94db1e78b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lower rows to see if we get double descent.\n",
    "# The interpolation threshold is at 14/2 - 1 intercept = 5 columns.\n",
    "num_sampled_rows = 14"
   ],
   "id": "b4c7e84e0717b5d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_by_num_cols(num_sampled_columns_local):\n",
    "    return sample_eval.sample_and_calc_metric(X, y, num_sampled_rows, num_sampled_columns_local, train_proportion, model, my_metric, replace=False, random_state=random_state)['test']\n",
    "num_samples = 300\n",
    "train_proportion = 0.5\n",
    "metric_all_samples = []\n",
    "# This example won't converge because we have such a small data sst\n",
    "# so we catch the warning and ignore it here.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    for num_sampled_columns in range(1, X.shape[1]-1):\n",
    "        metric_all_samples.append((num_sampled_columns, [sample_by_num_cols(num_sampled_columns) for _ in range(num_samples)]))\n",
    "metric_means = [(col_val_tuple[0], np.mean(col_val_tuple[1])) for col_val_tuple in metric_all_samples]\n",
    "res = list(zip(*metric_means))\n",
    "num_cols = res[0]\n",
    "means = res[1]\n",
    "plt.scatter(num_cols, means)\n",
    "plt.xlabel(\"Num sampled columns\")\n",
    "plt.ylabel(\"Mean of \" + my_metric.__name__)\n",
    "plt.show()"
   ],
   "id": "b6023bd7410a189b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The bump up at 7 columns *might* be due to double descent, but we predicted it would happen at 6 columns, assuming this is fitting an intercept.",
   "id": "c6970a0c9bedc8ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let me squeeze harder by lowering the number of rows even more.  10 Rows means fitting on 5 rows, so the interpolation threshold will be at 4 columns.",
   "id": "b36737528a2dbb2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lower rows to see if we get double descent.\n",
    "num_sampled_rows = 10"
   ],
   "id": "75494cd346168074",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_by_num_cols(num_sampled_columns_local):\n",
    "    return sample_eval.sample_and_calc_metric(X, y, num_sampled_rows, num_sampled_columns_local, train_proportion, model, my_metric, replace=False, random_state=random_state)['test']\n",
    "num_samples = 300\n",
    "train_proportion = 0.5\n",
    "metric_all_samples = []\n",
    "# This example won't converge because we have such a small data sst\n",
    "# so we catch the warning and ignore it here.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    for num_sampled_columns in range(1, X.shape[1]-1):\n",
    "        metric_all_samples.append((num_sampled_columns, [sample_by_num_cols(num_sampled_columns) for _ in range(num_samples)]))\n",
    "metric_means = [(col_val_tuple[0], np.mean(col_val_tuple[1])) for col_val_tuple in metric_all_samples]\n",
    "res = list(zip(*metric_means))\n",
    "num_cols = res[0]\n",
    "means = res[1]\n",
    "plt.scatter(num_cols, means)\n",
    "plt.xlabel(\"Num sampled columns\")\n",
    "plt.ylabel(\"Mean of \" + my_metric.__name__)\n",
    "plt.show()"
   ],
   "id": "7be26c39dd327d5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "That does look double descent-ish thanks to bump up in test error at 5 columns.  However, that does not match the prediction of 4 columns being the interpolation threshold.\n",
    "\n",
    "I need to study the SGDRegressor-- not to mention the possible effect of the StandardScaler-- to understand the number of parameters estimated so I can predict and explain exactly when and where the bump up happens."
   ],
   "id": "74b99a968672a0bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Based on the shapes above, using a consistent estimation method, I argue that **double descent is real** and not merely the overlap of two U curves from two different estimation methods.",
   "id": "4a22aa4f0bf75508"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Appendix: Fun with an MLPRegressor",
   "id": "47cfebecdb620012"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now consider a simple one-layer, feed-forward neural net (MLP = multi-layer perceptron) that is fit with stochastic gradient descent.\n",
    "\n",
    "Warning: the activation function makes it non-linear."
   ],
   "id": "a3c35efaeb54298e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: scale hidden layer neurons to number of columns.\n",
    "model = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    MLPRegressor(hidden_layer_sizes=(4,), validation_fraction=0, solver=\"sgd\", random_state=0))"
   ],
   "id": "ab95da73f62a31b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_by_num_cols(num_sampled_columns_local):\n",
    "    return sample_eval.sample_and_calc_metric(X, y, num_sampled_rows, num_sampled_columns_local, train_proportion, model, my_metric, replace=False, random_state=random_state)['test']"
   ],
   "id": "8b4bea6b75119ecd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# First just look for the bias-variance U curve\n",
    "num_sampled_rows = 30"
   ],
   "id": "d79e72330759d6d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_by_num_cols(num_sampled_columns_local):\n",
    "    return sample_eval.sample_and_calc_metric(X, y, num_sampled_rows, num_sampled_columns_local, train_proportion, model, my_metric, replace=False, random_state=random_state)['test']\n",
    "num_samples = 400\n",
    "train_proportion = 0.5\n",
    "metric_all_samples = []\n",
    "# This example won't converge because we have such a small data sst\n",
    "# so we catch the warning and ignore it here.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    for num_sampled_columns in range(1, X.shape[1]-1):\n",
    "        metric_all_samples.append((num_sampled_columns, [sample_by_num_cols(num_sampled_columns) for _ in range(num_samples)]))\n",
    "metric_means = [(col_val_tuple[0], np.mean(col_val_tuple[1])) for col_val_tuple in metric_all_samples]\n",
    "res = list(zip(*metric_means))\n",
    "num_cols = res[0]\n",
    "means = res[1]\n",
    "plt.scatter(num_cols, means)\n",
    "plt.xlabel(\"Num sampled columns\")\n",
    "plt.ylabel(\"Mean of \" + my_metric.__name__)\n",
    "plt.show()"
   ],
   "id": "4c52d1d7618f4c64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This looks pretty U-shaped.",
   "id": "491dd4ec952e5d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lower the number of rows to look for double descent.\n",
    "num_sampled_rows = 10"
   ],
   "id": "9e60c80629ca8b77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_by_num_cols(num_sampled_columns_local):\n",
    "    return sample_eval.sample_and_calc_metric(X, y, num_sampled_rows, num_sampled_columns_local, train_proportion, model, my_metric, replace=False, random_state=random_state)['test']\n",
    "num_samples = 400\n",
    "train_proportion = 0.5\n",
    "metric_all_samples = []\n",
    "# This example won't converge because we have such a small data sst\n",
    "# so we catch the warning and ignore it here.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    for num_sampled_columns in range(1, X.shape[1]-1):\n",
    "        metric_all_samples.append((num_sampled_columns, [sample_by_num_cols(num_sampled_columns) for _ in range(num_samples)]))\n",
    "metric_means = [(col_val_tuple[0], np.mean(col_val_tuple[1])) for col_val_tuple in metric_all_samples]\n",
    "res = list(zip(*metric_means))\n",
    "num_cols = res[0]\n",
    "means = res[1]\n",
    "plt.scatter(num_cols, means)\n",
    "plt.xlabel(\"Num sampled columns\")\n",
    "plt.ylabel(\"Mean of \" + my_metric.__name__)\n",
    "plt.show()"
   ],
   "id": "5be719fb3fb28693",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I'm not sure what pattern I'm seeing.  But to do this in an apples-to-apples way with the prior regression studies, the number of hidden layer neurons should correspond to the number of sampled columns (because a weight is estimated for each neuron, and we want the number of parameters to scale, not just number of inputs).  Or maybe something else?  I'm still working on this one.",
   "id": "7ccd4e86eac9c2d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
